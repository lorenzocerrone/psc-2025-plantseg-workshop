{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from plotting import plot_comparison, plot_image, plot_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./ps_tasks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Setup workflow Tracing\n",
    "\n",
    "- Running the following cell will make sure that that the current workflow is \"empty\" and ready to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run-Inputs: [{}]\n",
      "Tasks: []\n"
     ]
    }
   ],
   "source": [
    "from plantseg.tasks.workflow_handler import workflow_handler\n",
    "\n",
    "workflow_handler.clean_dag()\n",
    "\n",
    "print(f\"Run-Inputs: {workflow_handler.dag.inputs}\")\n",
    "print(f\"Tasks: {workflow_handler.dag.list_tasks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import the input data\n",
    "\n",
    "- First, we need to import the input data. This is done by running the following cell.\n",
    "- Try to run the following cells with diffent inputs from the given test data (eg. [ovule_2d](https://drive.google.com/file/d/1Mfg3q-5Rj_oxLPUaqyTiqvVk9uKRB8xa/view?usp=sharing))\n",
    "- Be careful that some parementers like the `stack_layout` might need to be adjusted based on the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: P [MainThread] 2025-03-12 09:46:58,628 plantseg.io.io - No default found for , reverting to default loader with no voxel size reader.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/locerr/Projects/plantseg-workshop-psc-2025/PATH to your File'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[32m/var/folders/03/__d9tf214kl4v33h1010tmrh0d99n7/T/ipykernel_39101/3168919731.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m path = \u001b[33m\"PATH to your File\"\u001b[39m\n\u001b[32m      4\u001b[39m path = Path(path)\n\u001b[32m      5\u001b[39m \n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m ps_image = import_image_task(input_path=path, semantic_type=\u001b[33m'raw'\u001b[39m, stack_layout=\u001b[33m\"YX\"\u001b[39m, key=\u001b[33m\"raw\"\u001b[39m)\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m plot_image(ps_image.get_data(), title=\u001b[33m\"Raw Image\"\u001b[39m)\n\u001b[32m      9\u001b[39m \n",
      "\u001b[32m~/miniforge3/envs/plant-seg/lib/python3.12/site-packages/plantseg/tasks/workflow_handler.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    332\u001b[39m                     \u001b[38;5;66;03m# Replace the default value with the provided value\u001b[39;00m\n\u001b[32m    333\u001b[39m                     parameters[name] = arg\n\u001b[32m    334\u001b[39m \n\u001b[32m    335\u001b[39m             \u001b[38;5;66;03m# Execute the function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m             out_image = func(*args, **kwargs)\n\u001b[32m    337\u001b[39m \n\u001b[32m    338\u001b[39m             \u001b[38;5;66;03m# Parse the output\u001b[39;00m\n\u001b[32m    339\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m out_image \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m~/miniforge3/envs/plant-seg/lib/python3.12/site-packages/plantseg/tasks/io_tasks.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(input_path, semantic_type, stack_layout, image_name, key, m_slicing)\u001b[39m\n\u001b[32m     37\u001b[39m \n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m image_name \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     39\u001b[39m         image_name = input_path.stem\n\u001b[32m     40\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     return import_image(\n\u001b[32m     42\u001b[39m         path=input_path,\n\u001b[32m     43\u001b[39m         key=key,\n\u001b[32m     44\u001b[39m         image_name=image_name,\n",
      "\u001b[32m~/miniforge3/envs/plant-seg/lib/python3.12/site-packages/plantseg/core/image.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(path, key, image_name, semantic_type, stack_layout, m_slicing)\u001b[39m\n\u001b[32m    591\u001b[39m         semantic_type (str): Semantic type of the image, should be raw, segmentation, prediction \u001b[38;5;28;01mor\u001b[39;00m label\n\u001b[32m    592\u001b[39m         stack_layout (str): Layout of the image, should be YX, CYX, ZYX, CZYX \u001b[38;5;28;01mor\u001b[39;00m ZCYX\n\u001b[32m    593\u001b[39m         m_slicing (str): Slicing to apply to the image, should be a string \u001b[38;5;28;01mwith\u001b[39;00m the format [start:stop, ...] \u001b[38;5;28;01mfor\u001b[39;00m each dimension.\n\u001b[32m    594\u001b[39m     \"\"\"\n\u001b[32m--> \u001b[39m\u001b[32m595\u001b[39m     data, voxel_size = smart_load_with_vs(path, key)\n\u001b[32m    596\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m voxel_size \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    597\u001b[39m         voxel_size = VoxelSize()\n\u001b[32m    598\u001b[39m \n",
      "\u001b[32m~/miniforge3/envs/plant-seg/lib/python3.12/site-packages/plantseg/io/io.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(path, key, default)\u001b[39m\n\u001b[32m     89\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m load_zarr(path, key), read_zarr_voxel_size(path, key)\n\u001b[32m     90\u001b[39m \n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     92\u001b[39m         logger.warning(f\"No default found for {ext}, reverting to default loader with no voxel size reader.\")\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m default(path), \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[32m~/miniforge3/envs/plant-seg/lib/python3.12/site-packages/plantseg/io/tiff.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    124\u001b[39m \n\u001b[32m    125\u001b[39m     Returns:\n\u001b[32m    126\u001b[39m         np.ndarray: loaded data \u001b[38;5;28;01mas\u001b[39;00m numpy array\n\u001b[32m    127\u001b[39m     \"\"\"\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tifffile.imread(path)\n",
      "\u001b[32m~/miniforge3/envs/plant-seg/lib/python3.12/site-packages/tifffile/tifffile.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(files, selection, aszarr, key, series, level, squeeze, maxworkers, buffersize, mode, name, offset, size, pattern, axesorder, categories, imread, imreadargs, sort, container, chunkshape, chunkdtype, axestiled, ioworkers, chunkmode, fillvalue, zattrs, multiscales, omexml, out, out_inplace, _multifile, _useframes, **kwargs)\u001b[39m\n\u001b[32m   1217\u001b[39m         ):\n\u001b[32m   1218\u001b[39m             files = files[\u001b[32m0\u001b[39m]\n\u001b[32m   1219\u001b[39m \n\u001b[32m   1220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m isinstance(files, str) \u001b[38;5;28;01mor\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(files, Sequence):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m             with TiffFile(\n\u001b[32m   1222\u001b[39m                 files,\n\u001b[32m   1223\u001b[39m                 mode=mode,\n\u001b[32m   1224\u001b[39m                 name=name,\n",
      "\u001b[32m~/miniforge3/envs/plant-seg/lib/python3.12/site-packages/tifffile/tifffile.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, file, mode, name, offset, size, omexml, _multifile, _useframes, _parent, **is_flags)\u001b[39m\n\u001b[32m   4245\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m'invalid OME-XML'\u001b[39m)\n\u001b[32m   4246\u001b[39m             self._omexml = omexml\n\u001b[32m   4247\u001b[39m             self.is_ome = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   4248\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m4249\u001b[39m         fh = FileHandle(file, mode=mode, name=name, offset=offset, size=size)\n\u001b[32m   4250\u001b[39m         self._fh = fh\n\u001b[32m   4251\u001b[39m         self._multifile = \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m _multifile \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m bool(_multifile)\n\u001b[32m   4252\u001b[39m         self._files = {fh.name: self}\n",
      "\u001b[32m~/miniforge3/envs/plant-seg/lib/python3.12/site-packages/tifffile/tifffile.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, file, mode, name, offset, size)\u001b[39m\n\u001b[32m  14622\u001b[39m         self._offset = -\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m offset \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m offset\n\u001b[32m  14623\u001b[39m         self._size = -\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m size\n\u001b[32m  14624\u001b[39m         self._close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m  14625\u001b[39m         self._lock = NullContext()\n\u001b[32m> \u001b[39m\u001b[32m14626\u001b[39m         self.open()\n\u001b[32m  14627\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m self._fh \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[32m~/miniforge3/envs/plant-seg/lib/python3.12/site-packages/tifffile/tifffile.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m  14641\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m self._mode \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m {\u001b[33m'rb'\u001b[39m, \u001b[33m'r+b'\u001b[39m, \u001b[33m'wb'\u001b[39m, \u001b[33m'xb'\u001b[39m}:\n\u001b[32m  14642\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m ValueError(f'invalid mode {self._mode}')\n\u001b[32m  14643\u001b[39m             self._file = os.path.realpath(self._file)\n\u001b[32m  14644\u001b[39m             self._dir, self._name = os.path.split(self._file)\n\u001b[32m> \u001b[39m\u001b[32m14645\u001b[39m             self._fh = open(self._file, self._mode, encoding=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m  14646\u001b[39m             self._close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m  14647\u001b[39m             self._offset = max(\u001b[32m0\u001b[39m, self._offset)\n\u001b[32m  14648\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m isinstance(self._file, FileHandle):\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/locerr/Projects/plantseg-workshop-psc-2025/PATH to your File'"
     ]
    }
   ],
   "source": [
    "from plantseg.tasks.io_tasks import import_image_task\n",
    "\n",
    "path = Path(\"PATH to your File\")\n",
    "\n",
    "ps_image = import_image_task(input_path=path, semantic_type='raw', stack_layout=\"YX\", key=\"raw\")\n",
    "\n",
    "plot_image(ps_image.get_data(), title=\"Raw Image\")\n",
    "\n",
    "print(f\"Run-Inputs: {workflow_handler.dag.inputs}\")\n",
    "print(f\"Tasks: {workflow_handler.dag.list_tasks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Run a basic workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plantseg.io.voxelsize import VoxelSize\n",
    "from plantseg.tasks.dataprocessing_tasks import gaussian_smoothing_task, image_rescale_to_voxel_size_task, set_biggest_instance_to_zero_task\n",
    "from plantseg.tasks.prediction_tasks import unet_prediction_task\n",
    "from plantseg.tasks.segmentation_tasks import dt_watershed_task, clustering_segmentation_task\n",
    "\n",
    "\n",
    "smooth_image = gaussian_smoothing_task(image=ps_image, sigma=6.0)\n",
    "\n",
    "plot_comparison(ps_image.get_data(), smooth_image.get_data(), title1=\"Raw Image\", title2=\"Smooth Image\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Export image and save the workflow\n",
    "\n",
    "- Runnning the following cell will export the image of the workflow and save the workflow file in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plantseg.tasks.io_tasks import export_image_task\n",
    "\n",
    "export_image_task(image=smooth_image, export_directory=\"./\", name_pattern='{file_name}_export')\n",
    "\n",
    "workflow_handler.save_to_yaml(path=\"./base_workflow.yaml\")\n",
    "\n",
    "print(f\"Run-Inputs: {workflow_handler.dag.inputs}\")\n",
    "print(\"Tasks: \")\n",
    "for task in workflow_handler.dag.list_tasks:\n",
    "    print(f'- {task}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 Run the workflow from the command line\n",
    "\n",
    "- Run the following command in the terminal to run the workflow from the command line.\n",
    "```bash\n",
    "plantseg --config base_workflow.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Create a more complex workflow\n",
    "\n",
    "- You can create a more complex workflow by adding more steps to the workflow.\n",
    "- Try for example to use the `unet_prediction_tak` and the `dt_watershed_task` to segment one of the test images.\n",
    "- To check the possible kewords arguments for each task you can see our [api documentation](https://kreshuklab.github.io/plant-seg/chapters/python_api/tasks/io_tasks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plantseg.io.voxelsize import VoxelSize\n",
    "from plantseg.tasks.dataprocessing_tasks import gaussian_smoothing_task, image_rescale_to_voxel_size_task, set_biggest_instance_to_zero_task\n",
    "from plantseg.tasks.prediction_tasks import unet_prediction_task\n",
    "from plantseg.tasks.segmentation_tasks import dt_watershed_task, clustering_segmentation_task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plantseg.tasks.workflow_handler import workflow_handler\n",
    "\n",
    "workflow_handler.clean_dag()\n",
    "\n",
    "print(f\"Run-Inputs: {workflow_handler.dag.inputs}\")\n",
    "print(f\"Tasks: {workflow_handler.dag.list_tasks}\")\n",
    "\n",
    "\n",
    "##############################################\n",
    "#\n",
    "# Place your code here\n",
    "#\n",
    "##############################################\n",
    "\n",
    "\n",
    "workflow_handler.save_to_yaml(path=\"./full_workflow.yaml\")\n",
    "\n",
    "print(f\"Run-Inputs: {workflow_handler.dag.inputs}\")\n",
    "print(\"Tasks: \")\n",
    "for task in workflow_handler.dag.list_tasks:\n",
    "    print(f'- {task}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Use plantseg functionals to interact with other libraries\n",
    "\n",
    "- You can use the plantseg functionals to interact with other libraries like napari, scikit-image, etc.\n",
    "- Plantseg functionals simply work with numpy arrays\n",
    "- Replace the `random_image` with an image from the test data and try to use the functionals to segment the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari \n",
    "# Start a napari viewer\n",
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: P [MainThread] 2025-03-12 09:54:10,916 plantseg.functionals.prediction.prediction - Zoo prediction: Running model from PlantSeg official zoo.\n",
      "INFO: P [MainThread] 2025-03-12 09:54:10,958 plantseg.functionals.prediction.prediction - Computing theoretical minimum halo from model.\n",
      "INFO: P [MainThread] 2025-03-12 09:54:21,944 plantseg.functionals.prediction.prediction - For raw in shape (950, 1100): set patch shape (1, 950, 1100), set halo shape (0, 0, 0)\n",
      "INFO: P [MainThread] 2025-03-12 09:54:24,276 plantseg.functionals.prediction.utils.array_predictor - Using batch size of 1 for prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.74s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Image layer 'prediction [1]' at 0x392178050>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from plantseg.functionals.prediction import unet_prediction\n",
    "from plantseg.functionals.dataprocessing import normalize_01, image_gaussian_smoothing, image_rescale\n",
    "from plantseg.functionals.segmentation import dt_watershed, gasp, multicut, mutex_ws\n",
    "from plantseg.io import smart_load\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "random_image = np.random.rand(512, 512)\n",
    "# test_image = smart_load(Path(\"Path to your image\"))\n",
    "\n",
    "prediction = unet_prediction(raw=random_image, \n",
    "                             input_layout=\"YX\",\n",
    "                             model_name=\"confocal_2D_unet_ovules_ds2x\",\n",
    "                             # patch=(1, 64, 64),\n",
    "                             #patch_halo=(0, 0, 0),\n",
    "                             model_id=None, device=\"mps\")\n",
    "\n",
    "# you can play with the image contrast and you can see the effect of\n",
    "# patch and patch_halo on the result\n",
    "viewer.add_image(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
